from flask import Flask, request, jsonify
from langchain_upstage import UpstageEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.prompts import ChatPromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI
import os
import dotenv
import json

dotenv.load_dotenv()

app = Flask(__name__)

# Embeddings ëª¨ë¸ ì„¤ì •
us_model = UpstageEmbeddings(
    api_key=os.getenv("UPSTAGE_API_KEY"),
    model="solar-embedding-1-large"
)

# ë°ì´í„°ë² ì´ìŠ¤ ë””ë ‰í„°ë¦¬ ë§¤í•‘
DB_DIRECTORIES = {
    "ko": "database/kr_database",
    "en": "database/eng_database",
    "fr": "database/fre_database",
    "zh": "database/cha_database",
    "de": "database/ger_database",
    "ja": "database/jp_database",
    "ru": "database/rus_database",
    "es": "database/spn_database"
}

# LLM ëª¨ë¸ ì„¤ì •
llm = ChatGoogleGenerativeAI(
    model=os.getenv("MODEL"),
    temperature=float(os.getenv("TEMPERATURE")),
    top_p=float(os.getenv("TOP_P"))
)


# Retriever ì„¤ì •
def get_retriever(language_code):
    persist_directory = DB_DIRECTORIES.get(language_code, "database/kr_database")
    vector_store = Chroma(persist_directory=persist_directory, embedding_function=us_model)
    return vector_store.as_retriever(search_type="mmr", search_kwargs={"k": 50, "fetch_k": 100, "lambda": 0.1})


def llm_filter(query, pages):
    try:
        # LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt_template = ChatPromptTemplate.from_template(
            "ê²€ìƒ‰ ì¿¼ë¦¬ì™€ ê°€ì¥ ê´€ë ¨ ìˆëŠ” ê²°ê³¼ë§Œ ë°˜í™˜í•˜ì„¸ìš”.\n\nê²€ìƒ‰ ì¿¼ë¦¬: {query}\n\nê²°ê³¼ ëª©ë¡:\n{results}"
        )

        # í˜ì´ì§€ ëª©ë¡ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
        formatted_pages = "\n".join(
            f"* {page.metadata.get('contentId', 'N/A')} - {page.page_content.split("\n")[0].replace('[ì œëª©] ', '').strip()}"
            for page in pages
        )

        # LLM í˜¸ì¶œ
        prompt = prompt_template.format(query=query, results=formatted_pages)
        response = llm.invoke(prompt)

        # ğŸ” LLM ì‘ë‹µ ë‚´ìš© ì¶œë ¥
        response_text = response.content.strip()

        # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        selected_ids = set(line.split("-")[0].strip("* ").strip() for line in response_text.split("\n") if line.strip())

        # ì„ íƒëœ contentIdë§Œ ë°˜í™˜
        return [{"contentId": page.metadata["contentId"]} for page in pages if
                page.metadata["contentId"] in selected_ids]

    except Exception as e:
        print(f"[LLM Filter Error] {e}")
        return []


@app.route("/places/search", methods=["POST"])
def search_places():
    try:
        data = request.json
        query = data["query"]
        language_code = data.get("languageCode", "ko")

        # Retriever ì„¤ì •
        retriever = get_retriever(language_code)
        pages = retriever.invoke([query])

        # LLM í•„í„°ë§
        filtered_metadata = llm_filter(query, pages)

        # ìµœì¢… ê²°ê³¼ ë°˜í™˜
        return jsonify(filtered_metadata)
    except KeyError as e:
        print(f"[KeyError] Missing required key: {e}")
        return jsonify({"error": f"Missing required key: {e}"}), 400
    except Exception as e:
        print(f"[Exception] {e}")
        return jsonify({"error": str(e)}), 500


if __name__ == "__main__":
    app.run(port=5000, debug=True)
